{"name":"Fractalis-AR","tagline":"Augmented reality experiment with fractals","body":"# Fractalis-AR\r\n\r\nEste es un experimento de [Realidad Aumentada](https://es.wikipedia.org/wiki/Realidad_aumentada) en el que se mezcla tecnología y arte. Tanto en lo concreto como en lo abstracto.\r\n\r\nEn lo concreto: existe hardware, software, imágenes y el diseño de una instalación artística. En lo abstracto, la ciencia y la tecnología se acercan al arte, de la mano de los fractales y el glitch, ínstándonos a cuestionar ¿qué es lo real? ¿cómo luce el infinito?\r\n\r\nEl proyecto nace para el trabajo final de la carrera de Bellas Artes, de [Rocío Rojas Leighton](https://www.facebook.com/rocio.mintaka).\r\n\r\n![](http://imgur.com/YysggxY)\r\n\r\n## Realidad\r\nA modo general, uno de los objetivos principales del proyecto es el de montar una instalación (puede ser una habitación, pasillo, salón, etc) en la que se captan datos de vídeo y de distintos sensores. Estos se combinan y muestran, continuamente, en tiempo real, con secuencias de imágenes pre-generadas.\r\n\r\nLos datos de los sensores son usados para controlar el proceso de mezcla de las imágenes: tanto para seleccionar con qué imagen será _aumentado_ cada frame de video, como para definir cómo serán combinadas las dos imágenes.\r\n\r\nEl resultado, una secuencia de imágenes (video) con _realidad aumentada_, puede guardarse en un archivo, proyectarse, verse en un monitor o distribuirse por la web mediante streaming de video en tiempo real.\r\n\r\nTodo este proceso es dirigido por un programa escrito específicamente para este proyecto (que puede obtenerse [aquí](https://github.com/cmdelatorre/fractalisar)).\r\n\r\n### Arduino, Python y OpenCV\r\n\r\nLa placa [Arduino](http://www.arduino.cc/) es perfecta para este proyecto porque es muy fácil de utilizar y provee la capacidad de conectar sensores muy variados. Además puede comunicarse fácilmente con la computadora mediante un puerto USB o por la red (Ethernet o WiFi).\r\n\r\nEl programa que conecta todas las partes fue escrito en el lenguaje de programación [Python](https://www.python.org/). Entre otras ventajas de esta desición, está el hecho de que se puede usar la librería [OpenCV](http://opencv.org/) que facilita enormemente el proceso de trabajar con video e imágenes.\r\n\r\n\r\n### Posibilidades\r\n\r\nMás allá de la implementación existente, el proyecto permite una infinidad de posibilidades. Tanto el hardware como el software pueden adaptarse fácilmente para obtener resultados muy distintos.\r\n\r\nLas imágenes para _aumentar_ la realidad pueden obtenerse a partir de archivos pre-generados, de algún video o incluso generarse automáticamente (aunque esta última opción puede ser complicada por la necesidad de muchos recursos de cómputo).\r\n\r\nCon respecto a los sensores, puede utilizarse básicamente cualquiera disponible: de distancia, de iluminación, de movimiento, de presión, micrófonos, botones, otras cámaras, etc. De esta manera pueden diseñarse instalaciones muy complejas, que provean infintas señales o datos al programa.\r\n\r\nTodos estos datos parametrizan diversos procesos:\r\n * **Selección**: la selección de la imagen para mezclar con el frame de video. Pueden haber distintas fuentes de imágenes que se utilicen en distintos momentos o que a veces no se requiera modificar el video original.\r\n * **Transformación**: las transformaciones y filtros que se aplicarán a esta imagen o al frame de video real. Hay infinidad de cosas que pueden hacerse sobre las imágenes antes de mezclarlas (transformaciones geométricas, de colores, etc.)\r\n * **Mezcla**: el algoritmo que mezcla ambas imágenes puede hacerlo de muchas formas: superponiendo partes de una imagen a la otra, reemplazando pixels con diversos criterios, siguiendo algún _marcador_ predefinido, etc.\r\n\r\nLo anteriormente descripto son ejemplos de cosas que podrían hacerse con relativamente poco trabajo.\r\n\r\n\r\n## Aumentada\r\nMuestra de los fractales y link a datos\r\n\r\n### Fractales\r\n\r\n### Glitch\r\n\r\n# Instalación: primer prototipo funcional\r\n\r\nTodo este proceso fue realizado (y puede ser replicado) utilizando una cámara web, una placa Arduino y un proyector conectados a una computadora corriendo un software escrito específicamente para este proyecto (que puede obtenerse [aquí](https://github.com/cmdelatorre/fractalisar)).\r\nEn esta implementación en particular, se utilizó un sensor ultrasónico de \r\n\r\n# Autores\r\nRo, Juan y @cmdelatorre","google":"UA-64327958-1","note":"Don't delete this file! It's used internally to help with page regeneration."}